{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04e482c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f2672fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names_es_ar.txt').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4a792b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(\"\".join(words))))\n",
    "n = len(chars)\n",
    "\n",
    "stoi = {s: i + 1 for i, s in enumerate(chars)}\n",
    "stoi[\".\"] = 0\n",
    "\n",
    "itos = {i: s for s, i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "891ddcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples: 1461211\n"
     ]
    }
   ],
   "source": [
    "N = torch.zeros((n + 1, n + 1), dtype=torch.int32)\n",
    "compile = 0\n",
    "xs, ys = [], []\n",
    "for w in words[:]:\n",
    "    chs = [\".\"] + list(w) + [\".\"]\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        N[ix1, ix2] += 1\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "print(\"number of examples:\", num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eca7dced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  4, 33,  ..., 40, 40, 29])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1b02398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4, 33, 42,  ..., 40, 29,  0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "975da2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize neural network\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((n + 1, n + 1), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b7214c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 4.75836181640625\n",
      "loss: 4.244924068450928\n",
      "loss: 3.9027631282806396\n",
      "loss: 3.661356210708618\n",
      "loss: 3.4833943843841553\n",
      "loss: 3.353160858154297\n",
      "loss: 3.255164384841919\n",
      "loss: 3.17826509475708\n",
      "loss: 3.1149518489837646\n",
      "loss: 3.061269998550415\n",
      "loss: 3.0144143104553223\n",
      "loss: 2.9731225967407227\n",
      "loss: 2.9359796047210693\n",
      "loss: 2.9027347564697266\n",
      "loss: 2.8722891807556152\n",
      "loss: 2.8448984622955322\n",
      "loss: 2.819451093673706\n",
      "loss: 2.796522378921509\n",
      "loss: 2.774888038635254\n",
      "loss: 2.755424737930298\n",
      "loss: 2.7367441654205322\n",
      "loss: 2.7199718952178955\n",
      "loss: 2.7036213874816895\n",
      "loss: 2.688995599746704\n",
      "loss: 2.6745312213897705\n",
      "loss: 2.661731719970703\n",
      "loss: 2.6487605571746826\n",
      "loss: 2.6373720169067383\n",
      "loss: 2.6255931854248047\n",
      "loss: 2.6153807640075684\n",
      "loss: 2.6046831607818604\n",
      "loss: 2.5955145359039307\n",
      "loss: 2.5856781005859375\n",
      "loss: 2.5773861408233643\n",
      "loss: 2.5683305263519287\n",
      "loss: 2.5607569217681885\n",
      "loss: 2.552391529083252\n",
      "loss: 2.5454800128936768\n",
      "loss: 2.537705659866333\n",
      "loss: 2.5314438343048096\n",
      "loss: 2.5241763591766357\n",
      "loss: 2.5183541774749756\n",
      "loss: 2.5115392208099365\n",
      "loss: 2.5061864852905273\n",
      "loss: 2.4998319149017334\n",
      "loss: 2.4949207305908203\n",
      "loss: 2.4889512062072754\n",
      "loss: 2.484445333480835\n",
      "loss: 2.4788637161254883\n",
      "loss: 2.474722146987915\n",
      "loss: 2.4694385528564453\n",
      "loss: 2.4656319618225098\n",
      "loss: 2.460615396499634\n",
      "loss: 2.457082509994507\n",
      "loss: 2.4523653984069824\n",
      "loss: 2.4490671157836914\n",
      "loss: 2.444601535797119\n",
      "loss: 2.4415740966796875\n",
      "loss: 2.4372990131378174\n",
      "loss: 2.4344847202301025\n",
      "loss: 2.4304356575012207\n",
      "loss: 2.427826166152954\n",
      "loss: 2.4240028858184814\n",
      "loss: 2.4216041564941406\n",
      "loss: 2.41792631149292\n",
      "loss: 2.4156761169433594\n",
      "loss: 2.412175178527832\n",
      "loss: 2.4100944995880127\n",
      "loss: 2.4067463874816895\n",
      "loss: 2.4048242568969727\n",
      "loss: 2.4015915393829346\n",
      "loss: 2.399782657623291\n",
      "loss: 2.396724224090576\n",
      "loss: 2.3950564861297607\n",
      "loss: 2.3920860290527344\n",
      "loss: 2.390544891357422\n",
      "loss: 2.3876912593841553\n",
      "loss: 2.3862531185150146\n",
      "loss: 2.3835136890411377\n",
      "loss: 2.3822219371795654\n",
      "loss: 2.3795695304870605\n",
      "loss: 2.378382682800293\n",
      "loss: 2.375807762145996\n",
      "loss: 2.3747103214263916\n",
      "loss: 2.3722434043884277\n",
      "loss: 2.3712151050567627\n",
      "loss: 2.3688554763793945\n",
      "loss: 2.3678860664367676\n",
      "loss: 2.3655519485473633\n",
      "loss: 2.3646726608276367\n",
      "loss: 2.3624062538146973\n",
      "loss: 2.3615918159484863\n",
      "loss: 2.3593993186950684\n",
      "loss: 2.3586437702178955\n",
      "loss: 2.3565139770507812\n",
      "loss: 2.355825185775757\n",
      "loss: 2.3537559509277344\n",
      "loss: 2.3531248569488525\n",
      "loss: 2.351112127304077\n",
      "loss: 2.350534200668335\n",
      "loss: 2.3485794067382812\n",
      "loss: 2.348048686981201\n",
      "loss: 2.34614896774292\n",
      "loss: 2.345724105834961\n",
      "loss: 2.3438804149627686\n",
      "loss: 2.3435003757476807\n",
      "loss: 2.341620683670044\n",
      "loss: 2.341226816177368\n",
      "loss: 2.339460611343384\n",
      "loss: 2.3391435146331787\n",
      "loss: 2.3374011516571045\n",
      "loss: 2.3371474742889404\n",
      "loss: 2.335397481918335\n",
      "loss: 2.335144519805908\n",
      "loss: 2.3334715366363525\n",
      "loss: 2.3333113193511963\n",
      "loss: 2.3316237926483154\n",
      "loss: 2.3314404487609863\n",
      "loss: 2.329836845397949\n",
      "loss: 2.329738140106201\n",
      "loss: 2.328159809112549\n",
      "loss: 2.3280417919158936\n",
      "loss: 2.3264503479003906\n",
      "loss: 2.3263678550720215\n",
      "loss: 2.324869155883789\n",
      "loss: 2.324840545654297\n",
      "loss: 2.323315382003784\n",
      "loss: 2.3233144283294678\n",
      "loss: 2.3218204975128174\n",
      "loss: 2.3218448162078857\n",
      "loss: 2.320375442504883\n",
      "loss: 2.3204312324523926\n",
      "loss: 2.318976640701294\n",
      "loss: 2.3190462589263916\n",
      "loss: 2.317629337310791\n",
      "loss: 2.317723512649536\n",
      "loss: 2.316318988800049\n",
      "loss: 2.316434144973755\n",
      "loss: 2.3150529861450195\n",
      "loss: 2.315189838409424\n",
      "loss: 2.3138267993927\n",
      "loss: 2.313981533050537\n",
      "loss: 2.3126754760742188\n",
      "loss: 2.312814950942993\n",
      "loss: 2.31148362159729\n",
      "loss: 2.311677932739258\n",
      "loss: 2.3104074001312256\n",
      "loss: 2.310579776763916\n",
      "loss: 2.309283971786499\n",
      "loss: 2.309508800506592\n",
      "loss: 2.3082728385925293\n",
      "loss: 2.308513879776001\n",
      "loss: 2.3072776794433594\n",
      "loss: 2.30749773979187\n",
      "loss: 2.3062829971313477\n",
      "loss: 2.306523561477661\n",
      "loss: 2.30531907081604\n",
      "loss: 2.3055756092071533\n",
      "loss: 2.304384231567383\n",
      "loss: 2.3046529293060303\n",
      "loss: 2.3034796714782715\n",
      "loss: 2.303753137588501\n",
      "loss: 2.3025941848754883\n",
      "loss: 2.3028829097747803\n",
      "loss: 2.301738977432251\n",
      "loss: 2.3020386695861816\n",
      "loss: 2.3008995056152344\n",
      "loss: 2.30120849609375\n",
      "loss: 2.300090789794922\n",
      "loss: 2.3004088401794434\n",
      "loss: 2.2992959022521973\n",
      "loss: 2.2996292114257812\n",
      "loss: 2.298523187637329\n",
      "loss: 2.29886794090271\n",
      "loss: 2.297775983810425\n",
      "loss: 2.298125982284546\n",
      "loss: 2.297044038772583\n",
      "loss: 2.29740309715271\n",
      "loss: 2.2963314056396484\n",
      "loss: 2.296698570251465\n",
      "loss: 2.2956361770629883\n",
      "loss: 2.296010732650757\n",
      "loss: 2.294959306716919\n",
      "loss: 2.295339345932007\n",
      "loss: 2.294299364089966\n",
      "loss: 2.294687032699585\n",
      "loss: 2.2936534881591797\n",
      "loss: 2.2940497398376465\n",
      "loss: 2.2930238246917725\n",
      "loss: 2.2934277057647705\n",
      "loss: 2.292410135269165\n",
      "loss: 2.292818784713745\n",
      "loss: 2.291811466217041\n",
      "loss: 2.2922370433807373\n",
      "loss: 2.2912180423736572\n",
      "loss: 2.291646957397461\n",
      "loss: 2.290651798248291\n",
      "loss: 2.291088104248047\n",
      "loss: 2.290088176727295\n",
      "loss: 2.290525436401367\n",
      "loss: 2.2895078659057617\n",
      "loss: 2.289994478225708\n",
      "loss: 2.2890055179595947\n",
      "loss: 2.289456605911255\n",
      "loss: 2.2884514331817627\n",
      "loss: 2.288949728012085\n",
      "loss: 2.2879722118377686\n",
      "loss: 2.288433074951172\n",
      "loss: 2.2874412536621094\n",
      "loss: 2.2879481315612793\n",
      "loss: 2.286998987197876\n",
      "loss: 2.287461996078491\n",
      "loss: 2.2865071296691895\n",
      "loss: 2.28698992729187\n",
      "loss: 2.2860517501831055\n",
      "loss: 2.286550760269165\n",
      "loss: 2.2855875492095947\n",
      "loss: 2.28607177734375\n",
      "loss: 2.285127878189087\n",
      "loss: 2.285627841949463\n",
      "loss: 2.2847023010253906\n",
      "loss: 2.2852156162261963\n",
      "loss: 2.2842674255371094\n",
      "loss: 2.2847626209259033\n",
      "loss: 2.2838497161865234\n",
      "loss: 2.2843687534332275\n",
      "loss: 2.2834298610687256\n",
      "loss: 2.283933401107788\n",
      "loss: 2.2830147743225098\n",
      "loss: 2.28353214263916\n",
      "loss: 2.2826313972473145\n",
      "loss: 2.2831597328186035\n",
      "loss: 2.2822372913360596\n",
      "loss: 2.2827720642089844\n",
      "loss: 2.2818548679351807\n",
      "loss: 2.2823963165283203\n",
      "loss: 2.2814767360687256\n",
      "loss: 2.2820217609405518\n",
      "loss: 2.281109094619751\n",
      "loss: 2.2816555500030518\n",
      "loss: 2.280748128890991\n",
      "loss: 2.2813000679016113\n",
      "loss: 2.280390977859497\n",
      "loss: 2.280945301055908\n",
      "loss: 2.2800452709198\n",
      "loss: 2.280597448348999\n",
      "loss: 2.2797038555145264\n",
      "loss: 2.280259847640991\n",
      "loss: 2.279367208480835\n",
      "loss: 2.2799272537231445\n",
      "loss: 2.2790367603302\n",
      "loss: 2.279599666595459\n",
      "loss: 2.278712272644043\n",
      "loss: 2.27927827835083\n",
      "loss: 2.278393268585205\n",
      "loss: 2.2789623737335205\n",
      "loss: 2.278080463409424\n",
      "loss: 2.278651714324951\n",
      "loss: 2.2777726650238037\n",
      "loss: 2.278346061706543\n",
      "loss: 2.277470827102661\n",
      "loss: 2.278045415878296\n",
      "loss: 2.277172803878784\n",
      "loss: 2.2777507305145264\n",
      "loss: 2.2768800258636475\n",
      "loss: 2.2774605751037598\n",
      "loss: 2.27659273147583\n",
      "loss: 2.277174949645996\n",
      "loss: 2.2763140201568604\n",
      "loss: 2.276893138885498\n",
      "loss: 2.2760329246520996\n",
      "loss: 2.2766172885894775\n",
      "loss: 2.2757630348205566\n",
      "loss: 2.2763442993164062\n",
      "loss: 2.275489091873169\n",
      "loss: 2.276078701019287\n",
      "loss: 2.275228261947632\n",
      "loss: 2.2758138179779053\n",
      "loss: 2.27496337890625\n",
      "loss: 2.2755579948425293\n",
      "loss: 2.274709939956665\n",
      "loss: 2.2753000259399414\n",
      "loss: 2.2744576930999756\n",
      "loss: 2.27504825592041\n",
      "loss: 2.2742092609405518\n",
      "loss: 2.274801015853882\n",
      "loss: 2.273966073989868\n",
      "loss: 2.2746055126190186\n",
      "loss: 2.2737503051757812\n",
      "loss: 2.274364471435547\n",
      "loss: 2.27351450920105\n",
      "loss: 2.274139881134033\n",
      "loss: 2.273272752761841\n",
      "loss: 2.2738986015319824\n",
      "loss: 2.2730486392974854\n",
      "loss: 2.273679256439209\n",
      "loss: 2.272818088531494\n",
      "loss: 2.273442506790161\n",
      "loss: 2.2725961208343506\n",
      "loss: 2.2732322216033936\n",
      "loss: 2.2723727226257324\n",
      "loss: 2.2730014324188232\n",
      "loss: 2.2721595764160156\n",
      "loss: 2.2727956771850586\n",
      "loss: 2.271942138671875\n",
      "loss: 2.272570848464966\n",
      "loss: 2.271733283996582\n",
      "loss: 2.2723734378814697\n",
      "loss: 2.271522045135498\n",
      "loss: 2.2721543312072754\n",
      "loss: 2.271320343017578\n",
      "loss: 2.2719616889953613\n",
      "loss: 2.2711150646209717\n",
      "loss: 2.271761417388916\n",
      "loss: 2.2709150314331055\n",
      "loss: 2.2715632915496826\n",
      "loss: 2.2707176208496094\n",
      "loss: 2.2713675498962402\n",
      "loss: 2.2705230712890625\n",
      "loss: 2.2711751461029053\n",
      "loss: 2.270331859588623\n",
      "loss: 2.2709848880767822\n",
      "loss: 2.2701425552368164\n",
      "loss: 2.270796775817871\n",
      "loss: 2.269956350326538\n",
      "loss: 2.270611524581909\n",
      "loss: 2.2697763442993164\n",
      "loss: 2.2704250812530518\n",
      "loss: 2.2695939540863037\n",
      "loss: 2.2702457904815674\n",
      "loss: 2.2694144248962402\n",
      "loss: 2.270068645477295\n",
      "loss: 2.2692408561706543\n",
      "loss: 2.2698893547058105\n",
      "loss: 2.2690656185150146\n",
      "loss: 2.269717216491699\n",
      "loss: 2.268892526626587\n",
      "loss: 2.2695467472076416\n",
      "loss: 2.268725872039795\n",
      "loss: 2.2693753242492676\n",
      "loss: 2.2685556411743164\n",
      "loss: 2.2692108154296875\n",
      "loss: 2.268392562866211\n",
      "loss: 2.2690439224243164\n",
      "loss: 2.2682268619537354\n",
      "loss: 2.268882989883423\n",
      "loss: 2.2680680751800537\n",
      "loss: 2.2687201499938965\n",
      "loss: 2.267906665802002\n",
      "loss: 2.2685635089874268\n",
      "loss: 2.267751693725586\n",
      "loss: 2.268404722213745\n",
      "loss: 2.267594337463379\n",
      "loss: 2.26825213432312\n",
      "loss: 2.2674429416656494\n",
      "loss: 2.268097400665283\n",
      "loss: 2.267291307449341\n",
      "loss: 2.2679457664489746\n",
      "loss: 2.2671420574188232\n",
      "loss: 2.267796516418457\n",
      "loss: 2.266990900039673\n",
      "loss: 2.267652750015259\n",
      "loss: 2.2668473720550537\n",
      "loss: 2.2675044536590576\n",
      "loss: 2.2667038440704346\n",
      "loss: 2.2673628330230713\n",
      "loss: 2.2665610313415527\n",
      "loss: 2.267220973968506\n",
      "loss: 2.2664201259613037\n",
      "loss: 2.2670810222625732\n",
      "loss: 2.2662806510925293\n",
      "loss: 2.266941785812378\n",
      "loss: 2.266141653060913\n",
      "loss: 2.26680326461792\n",
      "loss: 2.2660069465637207\n",
      "loss: 2.266669511795044\n",
      "loss: 2.265871286392212\n",
      "loss: 2.2665369510650635\n",
      "loss: 2.265737295150757\n",
      "loss: 2.2664051055908203\n",
      "loss: 2.2656075954437256\n",
      "loss: 2.2662737369537354\n",
      "loss: 2.2654762268066406\n",
      "loss: 2.2661452293395996\n",
      "loss: 2.265347957611084\n",
      "loss: 2.2660176753997803\n",
      "loss: 2.265221357345581\n",
      "loss: 2.265890598297119\n",
      "loss: 2.265096664428711\n",
      "loss: 2.26576566696167\n",
      "loss: 2.2649729251861572\n",
      "loss: 2.265641689300537\n",
      "loss: 2.264850616455078\n",
      "loss: 2.265519142150879\n",
      "loss: 2.2647294998168945\n",
      "loss: 2.2653982639312744\n",
      "loss: 2.2646098136901855\n",
      "loss: 2.2652788162231445\n",
      "loss: 2.264491081237793\n",
      "loss: 2.2651607990264893\n",
      "loss: 2.264374256134033\n",
      "loss: 2.2650437355041504\n",
      "loss: 2.2642581462860107\n",
      "loss: 2.264927864074707\n",
      "loss: 2.2641446590423584\n",
      "loss: 2.264813184738159\n",
      "loss: 2.2640316486358643\n",
      "loss: 2.264699697494507\n",
      "loss: 2.263918876647949\n",
      "loss: 2.2645883560180664\n",
      "loss: 2.263808488845825\n",
      "loss: 2.264477252960205\n",
      "loss: 2.263699531555176\n",
      "loss: 2.264369010925293\n",
      "loss: 2.263589382171631\n",
      "loss: 2.2642600536346436\n",
      "loss: 2.2634825706481934\n",
      "loss: 2.2641537189483643\n",
      "loss: 2.263375759124756\n",
      "loss: 2.2640485763549805\n",
      "loss: 2.263270139694214\n",
      "loss: 2.2639434337615967\n",
      "loss: 2.2631664276123047\n",
      "loss: 2.2638399600982666\n",
      "loss: 2.263063907623291\n",
      "loss: 2.263735771179199\n",
      "loss: 2.2629621028900146\n",
      "loss: 2.263633966445923\n",
      "loss: 2.262861490249634\n",
      "loss: 2.2635343074798584\n",
      "loss: 2.262761116027832\n",
      "loss: 2.263434410095215\n",
      "loss: 2.262662887573242\n",
      "loss: 2.2633349895477295\n",
      "loss: 2.262516498565674\n",
      "loss: 2.263237714767456\n",
      "loss: 2.2624664306640625\n",
      "loss: 2.263143539428711\n",
      "loss: 2.2623705863952637\n",
      "loss: 2.263047218322754\n",
      "loss: 2.262277841567993\n",
      "loss: 2.262951135635376\n",
      "loss: 2.262134313583374\n",
      "loss: 2.2628586292266846\n",
      "loss: 2.262089490890503\n",
      "loss: 2.262767791748047\n",
      "loss: 2.2619969844818115\n",
      "loss: 2.2626750469207764\n",
      "loss: 2.261906623840332\n",
      "loss: 2.2625837326049805\n",
      "loss: 2.261768341064453\n",
      "loss: 2.262493133544922\n",
      "loss: 2.2617270946502686\n",
      "loss: 2.2624053955078125\n",
      "loss: 2.261638641357422\n",
      "loss: 2.2623164653778076\n",
      "loss: 2.261503219604492\n",
      "loss: 2.2622289657592773\n",
      "loss: 2.2614634037017822\n",
      "loss: 2.2621448040008545\n",
      "loss: 2.2613792419433594\n",
      "loss: 2.262127637863159\n",
      "loss: 2.261317729949951\n",
      "loss: 2.262065887451172\n",
      "loss: 2.2613449096679688\n",
      "loss: 2.2621114253997803\n",
      "loss: 2.261305570602417\n",
      "loss: 2.262014627456665\n",
      "loss: 2.261216640472412\n",
      "loss: 2.2619261741638184\n",
      "loss: 2.261110544204712\n",
      "loss: 2.2618536949157715\n",
      "loss: 2.26104998588562\n",
      "loss: 2.2617669105529785\n",
      "loss: 2.2609753608703613\n",
      "loss: 2.2616822719573975\n",
      "loss: 2.2608706951141357\n",
      "loss: 2.261613130569458\n",
      "loss: 2.2608120441436768\n",
      "loss: 2.261528968811035\n",
      "loss: 2.260739326477051\n",
      "loss: 2.2614474296569824\n",
      "loss: 2.2606217861175537\n",
      "loss: 2.2613508701324463\n",
      "loss: 2.260570526123047\n",
      "loss: 2.261305093765259\n",
      "loss: 2.260504722595215\n",
      "loss: 2.2612228393554688\n",
      "loss: 2.26043438911438\n",
      "loss: 2.2611446380615234\n",
      "loss: 2.2603347301483154\n",
      "loss: 2.261080265045166\n",
      "loss: 2.2602810859680176\n",
      "loss: 2.261000156402588\n",
      "loss: 2.260213613510132\n",
      "loss: 2.260923385620117\n",
      "loss: 2.2601161003112793\n",
      "loss: 2.2608609199523926\n",
      "loss: 2.2600648403167725\n",
      "loss: 2.2607836723327637\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 50\n",
    "L2_REGULARIZATION_STRENGTH = 0.01\n",
    "\n",
    "for k in range(500):\n",
    "\n",
    "    # forward pass\n",
    "    xenc = F.one_hot(xs, num_classes=n + 1).float()\n",
    "    logists = xenc @ W  # predict log-counts\n",
    "    counts = logists.exp()  # counts, equivalent to N\n",
    "    probs = counts / counts.sum(dim=1, keepdim=True)  # probabilities for next character\n",
    "    loss = (\n",
    "        -probs[torch.arange(num), ys].log().mean()\n",
    "        + L2_REGULARIZATION_STRENGTH * (W**2).mean()\n",
    "    )\n",
    "    print(f\"loss: {loss.item()}\")\n",
    "\n",
    "    # backward pass\n",
    "    W.grad = None  # set to zero the gradient\n",
    "    loss.backward()  # compute the gradient of the loss with respect to W\n",
    "\n",
    "    # update the weights\n",
    "    W.data += -LEARNING_RATE * W.grad  # update the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca72a1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa47158c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ca\n",
      "Br\n",
      "Rora\n",
      "SXindara\n",
      "Gí\n",
      "AyTJo\n",
      "Maicia\n",
      "Elera\n",
      "Na\n",
      "Mana\n"
     ]
    }
   ],
   "source": [
    "# Generate 10 samples, omitting the last character ('.') in the output\n",
    "num_samples = 10\n",
    "for _ in range(num_samples):\n",
    "    ix = 0\n",
    "    generated_indices = []\n",
    "    while True:\n",
    "        # One-hot encode the current index\n",
    "        xenc = F.one_hot(torch.tensor([ix]), num_classes=n + 1).float()\n",
    "        # Compute logits and probabilities\n",
    "        logits = xenc @ W\n",
    "        counts = logits.exp()\n",
    "        probs = counts / counts.sum(dim=1, keepdim=True)\n",
    "        # Sample the next character index from the probability distribution\n",
    "        ix = torch.multinomial(probs, num_samples=1, replacement=True, generator=g).item()\n",
    "        generated_indices.append(ix)\n",
    "        # If the sampled character is '.', break\n",
    "        if itos[ix] == '.':\n",
    "            break\n",
    "    # Convert indices to characters, omit the last character ('.'), and join to form the generated string\n",
    "    generated_string = ''.join([itos[i] for i in generated_indices[:-1]])\n",
    "    print(generated_string)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
